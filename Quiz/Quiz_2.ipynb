{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "023d037e-a2c2-43d5-84fc-4daa662b48b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 300), (25000, 300))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Set parameters for the dataset loading\n",
    "vocab_size = 10000  \n",
    "maxlen = 300     \n",
    "\n",
    "# Load the data\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "# Pad sequences so that they all have the same length\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e74e44-1100-4258-8fa6-0b29f4d5d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, 32, input_length=maxlen),  # Embedding layer\n",
    "    SimpleRNN(32),  # RNN layer with 32 units\n",
    "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf77def-ca89-4d84-82b1-0f57ae979842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 96ms/step - accuracy: 0.6489 - loss: 0.6137 - val_accuracy: 0.8200 - val_loss: 0.4259 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.8629 - loss: 0.3386 - val_accuracy: 0.8464 - val_loss: 0.3591 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.9050 - loss: 0.2483 - val_accuracy: 0.8488 - val_loss: 0.3828 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.9462 - loss: 0.1529 - val_accuracy: 0.8308 - val_loss: 0.4303 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.9683 - loss: 0.1032 - val_accuracy: 0.8346 - val_loss: 0.5029 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.9872 - loss: 0.0450 - val_accuracy: 0.8116 - val_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.9923 - loss: 0.0284 - val_accuracy: 0.8298 - val_loss: 0.6113 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.9979 - loss: 0.0119 - val_accuracy: 0.8110 - val_loss: 0.6866 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.9750 - loss: 0.0669 - val_accuracy: 0.8142 - val_loss: 0.6974 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.9942 - loss: 0.0221 - val_accuracy: 0.7772 - val_loss: 0.7967 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                    validation_split=0.2, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "797f644b-3395-4989-b9b3-81c29fcb2cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.7761 - loss: 0.7745\n",
      "Test Accuracy: 0.7811599969863892\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74d064-990e-4fb5-817b-02070fbe4983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with lr=0.01 and optimizer=<keras.src.optimizers.adam.Adam object at 0x000002631FC2B250>\n",
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 95ms/step - accuracy: 0.8105 - loss: 0.4906 - val_accuracy: 0.7042 - val_loss: 0.5815\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 94ms/step - accuracy: 0.8665 - loss: 0.3233 - val_accuracy: 0.6190 - val_loss: 0.8799\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 94ms/step - accuracy: 0.8802 - loss: 0.2838 - val_accuracy: 0.6874 - val_loss: 0.7716\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.9335 - loss: 0.1789 - val_accuracy: 0.7398 - val_loss: 0.7546\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.9564 - loss: 0.1241 - val_accuracy: 0.6816 - val_loss: 0.7974\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.9393 - loss: 0.1602 - val_accuracy: 0.6410 - val_loss: 0.8592\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.8655 - loss: 0.2951 - val_accuracy: 0.6268 - val_loss: 0.7056\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.7415 - loss: 0.5146 - val_accuracy: 0.6834 - val_loss: 0.6610\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.8227 - loss: 0.3944 - val_accuracy: 0.7378 - val_loss: 0.6047\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 94ms/step - accuracy: 0.7805 - loss: 0.4530 - val_accuracy: 0.6386 - val_loss: 0.7038\n",
      "Training with lr=0.01 and optimizer=<keras.src.optimizers.sgd.SGD object at 0x000002637F7B1610>\n",
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 95ms/step - accuracy: 0.7970 - loss: 0.4280 - val_accuracy: 0.6460 - val_loss: 0.7033\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 91ms/step - accuracy: 0.8024 - loss: 0.4196 - val_accuracy: 0.6424 - val_loss: 0.7107\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 76ms/step - accuracy: 0.8111 - loss: 0.4074 - val_accuracy: 0.6464 - val_loss: 0.7129\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 85ms/step - accuracy: 0.8128 - loss: 0.4040 - val_accuracy: 0.6520 - val_loss: 0.7158\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 90ms/step - accuracy: 0.8202 - loss: 0.3940 - val_accuracy: 0.6534 - val_loss: 0.7168\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.8197 - loss: 0.3967 - val_accuracy: 0.6552 - val_loss: 0.7177\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.8227 - loss: 0.3882 - val_accuracy: 0.6634 - val_loss: 0.7175\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 90ms/step - accuracy: 0.8265 - loss: 0.3814 - val_accuracy: 0.6650 - val_loss: 0.7160\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.8312 - loss: 0.3768 - val_accuracy: 0.6694 - val_loss: 0.7180\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.8354 - loss: 0.3704 - val_accuracy: 0.6748 - val_loss: 0.7140\n",
      "Training with lr=0.001 and optimizer=<keras.src.optimizers.adam.Adam object at 0x000002630184FBE0>\n",
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 95ms/step - accuracy: 0.8445 - loss: 0.3610 - val_accuracy: 0.6894 - val_loss: 0.6933\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 94ms/step - accuracy: 0.8691 - loss: 0.3190 - val_accuracy: 0.6990 - val_loss: 0.7093\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 96ms/step - accuracy: 0.8903 - loss: 0.2755 - val_accuracy: 0.7006 - val_loss: 0.7230\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 98ms/step - accuracy: 0.9085 - loss: 0.2429 - val_accuracy: 0.7108 - val_loss: 0.7325\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 98ms/step - accuracy: 0.9180 - loss: 0.2184 - val_accuracy: 0.7090 - val_loss: 0.7673\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 96ms/step - accuracy: 0.9310 - loss: 0.1924 - val_accuracy: 0.7038 - val_loss: 0.8136\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 97ms/step - accuracy: 0.9351 - loss: 0.1813 - val_accuracy: 0.7188 - val_loss: 0.8161\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 97ms/step - accuracy: 0.9470 - loss: 0.1568 - val_accuracy: 0.7186 - val_loss: 0.8365\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 96ms/step - accuracy: 0.9472 - loss: 0.1563 - val_accuracy: 0.7236 - val_loss: 0.8531\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.9599 - loss: 0.1265 - val_accuracy: 0.7218 - val_loss: 0.8835\n",
      "Training with lr=0.001 and optimizer=<keras.src.optimizers.sgd.SGD object at 0x00000263018788E0>\n",
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 95ms/step - accuracy: 0.9668 - loss: 0.1083 - val_accuracy: 0.7222 - val_loss: 0.8865\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.9670 - loss: 0.1095 - val_accuracy: 0.7230 - val_loss: 0.8886\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 97ms/step - accuracy: 0.9662 - loss: 0.1096 - val_accuracy: 0.6924 - val_loss: 0.9381\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 94ms/step - accuracy: 0.9609 - loss: 0.1246 - val_accuracy: 0.7184 - val_loss: 0.8845\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 94ms/step - accuracy: 0.9666 - loss: 0.1089 - val_accuracy: 0.7208 - val_loss: 0.8922\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 98ms/step - accuracy: 0.9665 - loss: 0.1070 - val_accuracy: 0.7234 - val_loss: 0.8948\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.9682 - loss: 0.1068 - val_accuracy: 0.7242 - val_loss: 0.8983\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 97ms/step - accuracy: 0.9645 - loss: 0.1111 - val_accuracy: 0.7240 - val_loss: 0.9004\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.9672 - loss: 0.1074 - val_accuracy: 0.7234 - val_loss: 0.8995\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 94ms/step - accuracy: 0.9673 - loss: 0.1092 - val_accuracy: 0.7222 - val_loss: 0.9001\n",
      "Training with lr=0.0001 and optimizer=<keras.src.optimizers.adam.Adam object at 0x000002630184FBE0>\n",
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 95ms/step - accuracy: 0.9686 - loss: 0.1089 - val_accuracy: 0.7224 - val_loss: 0.9077\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.9679 - loss: 0.1053 - val_accuracy: 0.7232 - val_loss: 0.9126\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.9677 - loss: 0.1078 - val_accuracy: 0.7232 - val_loss: 0.9169\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 84ms/step - accuracy: 0.9668 - loss: 0.1054 - val_accuracy: 0.7240 - val_loss: 0.9209\n",
      "Epoch 5/10\n",
      "\u001b[1m137/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9665 - loss: 0.1061"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# grid search \n",
    "for lr in [0.01, 0.001, 0.0001]:\n",
    "    for optimizer in [Adam(lr), SGD(lr)]:\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        print(f\"Training with lr={lr} and optimizer={optimizer}\")\n",
    "        model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4781a4b-f9e4-48c4-bc8a-a00d92ed185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f08ed1-d4a8-4c96-b284-0cda360434b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
